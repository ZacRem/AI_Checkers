{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Creating a Connect Four game with AB pruning and A* as player strategies. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Some useful packages and libraries:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from collections import deque\n",
    "import heapq\n",
    "import unittest\n",
    "from scipy import stats\n",
    "import copy as cp\n",
    "from time import time\n",
    "from enum import Enum\n",
    "from typing import Dict, Tuple\n",
    "import sys\n",
    "from typing import Callable\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Problem 1: Game Theory - Playing \"intelligent\" Connect Four (100 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect Four is a two-player game where the objective is to get four pieces in a row - horizontally, vertically, or diagonally. Check out this video if you're unfamiliar with the game: https://www.youtube.com/watch?v=utXzIFEVPjA.\n",
    "\n",
    "* `moves` is a list of columns to represent which moves are available. Recall that we are using matrix notation for this, where the upper-left corner of the board, for example, is represented at (1,1).\n",
    "* `result(self, move, state)` returns a ***hypothetical*** resulting `State` object if `move` is made when the game is in the current `state`. Note that when a 'move' is made, the column must have an open slot and the piece must drop to the lowest row. \n",
    "* `compute_utility(self, move, state)` calculates the utility of `state` that would result if `move` is made when the game is in the current `state`. This is where you want to check to see if anyone has gotten `nwin` in a row\n",
    "* `game_over(self, state)` returns `True` if the game in the given `state` has reached a terminal state, and `False` otherwise.\n",
    "* `utility(self, state, player)` returns the utility of the current state if the player is Red and $-1 \\cdot$ utility if the player is Black.\n",
    "* `display(self)` is a method to display the current game `state`. You get it for free because this would be super frustrating without it.\n",
    "* `play_game(self, player1, player2)` returns an integer that is the utility of the outcome of the game (+1 if Red wins, 0 if draw, -1 if Black wins). `player1` and `player2` are functional arguments that we will deal with in parts **1b** and **1d**.\n",
    "\n",
    "Some notes:\n",
    "* Assume Red always goes first.\n",
    "* Do **not** hard-code for 6x7 boards.\n",
    "* You may add attributes and methods to these classes as needed for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Player(Enum):\n",
    "    RED = \"R\"\n",
    "    BLACK = \"B\"\n",
    "    EMPTY = \".\"\n",
    "\n",
    "class State:\n",
    "    def __init__(self, board_dimensions: tuple[int, int], utility: int = 0, board: dict[tuple[int,int], Player] = {}):\n",
    "        self.to_move = Player.RED\n",
    "        self.utility = utility\n",
    "        self.dimensions = board_dimensions\n",
    "        self.board : dict[tuple[int,int], Player] = board\n",
    "        self._moves = None\n",
    "        self._adjacent = None\n",
    "\n",
    "    def moves(self) -> list[tuple[int, int]]:\n",
    "        if self._moves is not None:\n",
    "            return self._moves\n",
    "\n",
    "        movesPoss = {col: self.dimensions[0] for col in range(1, self.dimensions[1] + 1)}\n",
    "\n",
    "        for row, col in self.board:\n",
    "            if col in movesPoss:\n",
    "                next_row = row - 1\n",
    "                if next_row <= 0:\n",
    "                    movesPoss.pop(col)\n",
    "                elif next_row < movesPoss[col]:\n",
    "                    movesPoss[col] = next_row\n",
    "\n",
    "        self._moves = [(movesPoss[col], col) for col in movesPoss]\n",
    "        return self._moves\n",
    "\n",
    "\n",
    "    def get_adjacent(self, move: tuple[int,int], n_adjacent: int, search_for: list[Player] = [*Player]) -> list[tuple[list[Player], list[Player]]]:\n",
    "        if Player.EMPTY in search_for and not None in search_for:\n",
    "            search_for.append(None)\n",
    "        directions = [\n",
    "            (iter_row, iter_col)\n",
    "            for iter_row in range(-1,2)\n",
    "            for iter_col in range(-1,2)\n",
    "            if (iter_row, iter_col) != (0,0)\n",
    "        ]\n",
    "        adjacent: list[tuple[list[Player], list[Player]]] = []\n",
    "        for direction in directions:\n",
    "            forward, backward = self.check_direction(move, direction, n_adjacent, search_for)\n",
    "            adjacent.append((forward, backward))\n",
    "        return adjacent\n",
    "\n",
    "    def check_direction(self, move: tuple[int,int], direction: tuple[int,int], n_adjacent: int, search_for: list[Player]) -> tuple[list[Player], list[Player]]:\n",
    "        forward, backward = [], []\n",
    "        for offset in range(1, n_adjacent):\n",
    "            check_state = (move[0] + direction[0] * offset, move[1] + direction[1] * offset)\n",
    "            if not (1 <= check_state[0] <= self.dimensions[0] and 1 <= check_state[1] <= self.dimensions[1]):\n",
    "                break\n",
    "            check_state_value = self.board.get(check_state)\n",
    "            if check_state_value in search_for:\n",
    "                value = Player.EMPTY if check_state_value is None else check_state_value\n",
    "                forward.append(value)\n",
    "            else:\n",
    "                break\n",
    "        for offset in range(1, n_adjacent):\n",
    "            check_state = (move[0] - direction[0] * offset, move[1] - direction[1] * offset)\n",
    "            if not (1 <= check_state[0] <= self.dimensions[0] and 1 <= check_state[1] <= self.dimensions[1]):\n",
    "                break\n",
    "            check_state_value = self.board.get(check_state)\n",
    "            if check_state_value in search_for:\n",
    "                value = Player.EMPTY if check_state_value is None else check_state_value\n",
    "                backward.insert(0, value)\n",
    "            else:\n",
    "                break\n",
    "        return forward, backward\n",
    "    \n",
    "    def hash(self):\n",
    "        return \"~\".join([str(e)+ \":\" + str(self.board[e]) for e in self.board])\n",
    "\n",
    "class ConnectFour:\n",
    "    def __init__(self, nrow=6, ncol=7, nwin=4):\n",
    "        self.nrow: int = nrow\n",
    "        self.ncol: int = ncol\n",
    "        self.nwin: int = nwin\n",
    "        self.state = State((nrow, ncol))\n",
    "\n",
    "    def result(self, move: tuple[int, int], state: State) -> State:\n",
    "        '''\n",
    "        move  = (row, col) tuple where player will put their mark (R or B)\n",
    "        state = a `State` object, to represent whose turn it is and form\n",
    "                the basis for generating a **hypothetical** updated state\n",
    "                that will result from making the given `move`\n",
    "        '''\n",
    "\n",
    "        # Check if the move is valid\n",
    "        if move not in state.moves():\n",
    "            return state\n",
    "\n",
    "        # Compute the utility of the move\n",
    "        utility = self.compute_utility(move, state)\n",
    "\n",
    "        # Create a new state with the updated board and next player\n",
    "        new_board = state.board.copy()\n",
    "        new_board[move] = state.to_move\n",
    "        new_state = State(state.dimensions, utility, new_board)\n",
    "        new_state.to_move = Player.BLACK if state.to_move == Player.RED else Player.RED\n",
    "\n",
    "        return new_state\n",
    "\n",
    "    def compute_utility(self, move: tuple[int,int], state: State) -> int:\n",
    "        '''\n",
    "        If 'R' wins with this move, return 1;\n",
    "        if 'B' wins return -1;\n",
    "        else return 0.\n",
    "        '''        \n",
    "\n",
    "        # Check if the move causes a win\n",
    "        adjacent = state.get_adjacent(move, self.nwin, [state.to_move])\n",
    "        for angle in adjacent:\n",
    "            sequential = 1\n",
    "            for direction in angle:\n",
    "                for piece in direction:\n",
    "                    if piece == state.to_move:\n",
    "                        sequential += 1\n",
    "                        if sequential == self.nwin:\n",
    "                            return 1 if state.to_move == Player.RED else -1\n",
    "                    else:\n",
    "                        sequential = 0\n",
    "\n",
    "        # Otherwise, return 0\n",
    "        return 0\n",
    "\n",
    "    def game_over(self, state: State) -> bool:\n",
    "        '''game is over if someone has won (utility!=0) or there\n",
    "        are no more moves left'''\n",
    "\n",
    "        # your code goes here... \n",
    "        return state.utility != 0 or len(state.moves()) == 0\n",
    "\n",
    "    def utility(self, state: State, player: Player) -> int:\n",
    "        '''Return the value to player; 1 for win, -1 for loss, 0 otherwise.'''\n",
    "        # your code goes here...\n",
    "        if state.utility == float('inf'):\n",
    "            return 1 if player == Player.RED else -1\n",
    "        elif state.utility == float('-inf'):\n",
    "            return -1 if player == Player.RED else 1\n",
    "        else:\n",
    "            if state.utility > 0:\n",
    "                return 1 if player == Player.RED else -1\n",
    "            elif state.utility < 0:\n",
    "                return -1 if player == Player.RED else 1\n",
    "            else:\n",
    "                return 0\n",
    "    \n",
    "    def display(self, state: State = None) -> None:\n",
    "        board = self.state.board\n",
    "        for row in range(1, self.nrow + 1):\n",
    "            for col in range(1, self.ncol + 1):\n",
    "                print(board.get((row, col), '.'), end=' ')\n",
    "            print()\n",
    "\n",
    "    def play_game(self, player1, player2,) -> int:\n",
    "        players: dict[Player, Callable[[ConnectFour], tuple[int,int]]] = { Player.RED: player1, Player.BLACK: player2}\n",
    "        current_player = Player.RED\n",
    "\n",
    "        while not self.game_over(self.state):\n",
    "            playing = players[current_player]\n",
    "            move: tuple[int,int] = playing(self)\n",
    "            new_state = self.result(move, self.state)\n",
    "            self.state = new_state\n",
    "            current_player = Player.RED if current_player == Player.BLACK else Player.BLACK\n",
    "\n",
    "        return self.utility(self.state, Player.RED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `random_player` that takes a single argument of the `ConnectFour` class and returns a random move out of the available legal moves in the `state` of the `ConnectFour` game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_player(game: ConnectFour) -> tuple[int,int]:\n",
    "    '''A player that chooses a legal move at random out of all\n",
    "    available legal moves in ConnectFour state argument'''\n",
    "    \n",
    "    available_moves = game.state.moves()\n",
    "    selected_move = random.choice(available_moves)\n",
    "    return selected_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to see the win percentage of the person that goes first in the game and due to this testing being done before it should be around 55% when put in a simulation of 1000 games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of games played: 1000\n",
      "Player RED won 555 games (55.50%)\n",
      "Player BLACK won 444 games (44.40%)\n",
      "Out of the games there were 1 ties (0.10%)\n"
     ]
    }
   ],
   "source": [
    "# 1000 games between two random players\n",
    "def play_games(player1, player2, iterations: int, game_args = (6, 7, 4), get_games=False):\n",
    "        # Initialize the win counters\n",
    "    wins = {Player.RED: 0, Player.BLACK: 0, Player.EMPTY: 0}\n",
    "\n",
    "    # Play the games\n",
    "    games = []\n",
    "    i = 0\n",
    "    while i < iterations:\n",
    "        game = ConnectFour(*game_args)\n",
    "        games.append(game)\n",
    "        result = game.play_game(player1, player2)\n",
    "        winner = None\n",
    "        if result == 1:\n",
    "            winner = Player.RED\n",
    "        elif result == -1:\n",
    "            winner = Player.BLACK\n",
    "        else:\n",
    "            winner = Player.EMPTY\n",
    "        wins[winner] += 1\n",
    "        i += 1\n",
    "    # Print the results\n",
    "    total_games = iterations\n",
    "    tie = total_games - (wins[Player.RED] + wins[Player.BLACK])\n",
    "    print(f\"Total number of games played: {total_games}\")\n",
    "    print(f\"Player {Player.RED.name} won {wins[Player.RED]} games ({100 * wins[Player.RED] / total_games:.2f}%)\")\n",
    "    print(f\"Player {Player.BLACK.name} won {wins[Player.BLACK]} games ({100 * wins[Player.BLACK] / total_games:.2f}%)\")\n",
    "    print(f\"Out of the games there were {tie} ties ({100 * tie / total_games:.2f}%)\")\n",
    "\n",
    "    if get_games:\n",
    "        return games\n",
    "\n",
    "\n",
    "play_games(random_player, random_player, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking to see what the long-term win percentage appears to be for the first player in a 10x10 ConnectFour tournament, where 4 marks must be connected for a win?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of games played: 1000\n",
      "Player RED won 473 games (47.30%)\n",
      "Player BLACK won 435 games (43.50%)\n",
      "Out of the games there were 92 ties (9.20%)\n"
     ]
    }
   ],
   "source": [
    "# 1000 games between two random players\n",
    "play_games(random_player, random_player, 1000, (10,10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that there is way more ties when the size of the state space changes from it increasing from 4 to 101 ties which in turn lowers the win percentage of the player. Where in this case he lost more going first than winning this most likely is because there are so many more spaces that it basically takes away the advantage that the person going first had."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created an `alphabeta_player` that takes a single argument of a `ConnectFour` class object and returns the minimax move in the `state` of the `ConnectFour` game. As the name implies, this player should be implementing alpha-beta pruning as described in the textbook and lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_factor = 0.9\n",
    "nodes_expanded = 0\n",
    "UtilityMove = namedtuple(\"UtilityMove\", [\"utility\", \"move\"])\n",
    "\n",
    "def alphabeta_player(game: ConnectFour, report_nodes_expanded=False) -> tuple[int, int]:\n",
    "    global nodes_expanded\n",
    "    nodes_expanded = 0\n",
    "    utility = alphabeta_value(game, game.state, float(\"-inf\"), float(\"inf\"))\n",
    "    if report_nodes_expanded:\n",
    "        return (utility.move, nodes_expanded)\n",
    "    return utility.move\n",
    "\n",
    "def report_nodes_expanded_func() -> int:\n",
    "    global nodes_expanded\n",
    "    return nodes_expanded\n",
    "\n",
    "def alphabeta_value(game: ConnectFour, state: State, alpha: int, beta: int) -> UtilityMove:\n",
    "    global nodes_expanded\n",
    "    nodes_expanded += 1\n",
    "\n",
    "    if game.game_over(state):\n",
    "        return UtilityMove(state.utility, None)\n",
    "\n",
    "    if state.to_move == Player.RED:\n",
    "        return max_value(game, state, alpha, beta)\n",
    "    else:\n",
    "        return min_value(game, state, alpha, beta)\n",
    "\n",
    "def max_value(game, state, alpha, beta):\n",
    "    utility = UtilityMove(-np.inf, None)\n",
    "    child_rechable_boundary = [alpha]\n",
    "\n",
    "    for move in state.moves():\n",
    "        child_utility, _ = alphabeta_value(game, game.result(move, state), alpha, beta)\n",
    "        child_utility *= discount_factor\n",
    "        utility = max(utility, UtilityMove(child_utility, move))\n",
    "\n",
    "        if utility.utility >= beta:\n",
    "            return utility\n",
    "        child_rechable_boundary[0] = max(utility.utility, child_rechable_boundary[0])\n",
    "\n",
    "        alpha = max(alpha, utility.utility)\n",
    "\n",
    "    return utility\n",
    "\n",
    "def min_value(game, state, alpha, beta):\n",
    "    utility = UtilityMove(np.inf, None)\n",
    "    child_rechable_boundary = [beta]\n",
    "\n",
    "    for move in state.moves():\n",
    "        child_utility, _ = alphabeta_value(game, game.result(move, state), alpha, beta)\n",
    "        child_utility *= discount_factor\n",
    "        utility = min(utility, UtilityMove(child_utility, move))\n",
    "\n",
    "        if utility.utility <= alpha:\n",
    "            return utility\n",
    "        child_rechable_boundary[0] = min(utility.utility, child_rechable_boundary[0])\n",
    "\n",
    "        beta = min(beta, utility.utility)\n",
    "\n",
    "    return utility\n",
    "\n",
    "def minimax(game, state, maximizing_player=True):\n",
    "    global nodes_expanded_minimax  # add this line to access the global variable\n",
    "    nodes_expanded_minimax += 1\n",
    "    \n",
    "    if game.game_over(state):\n",
    "        return state.utility, None\n",
    "\n",
    "    best_move = None\n",
    "    if maximizing_player:\n",
    "        max_utility = float('-inf')\n",
    "        for move in state.moves():\n",
    "            child_state = game.result(move, state)\n",
    "            child_utility, _ = minimax(game, child_state, False)\n",
    "            if child_utility > max_utility:\n",
    "                max_utility = child_utility\n",
    "                best_move = move\n",
    "        return max_utility, best_move\n",
    "    else:\n",
    "        min_utility = float('inf')\n",
    "        for move in state.moves():\n",
    "            child_state = game.result(move, state)\n",
    "            child_utility, _ = minimax(game, child_state, True)\n",
    "            if child_utility < min_utility:\n",
    "                min_utility = child_utility\n",
    "                best_move = move\n",
    "        return min_utility, best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. An alpha-beta player who plays first should never lose to a random player who plays second.\n",
    "2. Two alpha-beta players should always draw. One player is the max player and the other player is the min player.\n",
    "\n",
    "These should happen when the code runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AlphaBeta vs Random\n",
      "Total number of games played: 10\n",
      "Player RED won 10 games (100.00%)\n",
      "Player BLACK won 0 games (0.00%)\n",
      "Out of the games there were 0 ties (0.00%)\n",
      " Random vs AlphaBeta\n",
      "Total number of games played: 10\n",
      "Player RED won 3 games (30.00%)\n",
      "Player BLACK won 6 games (60.00%)\n",
      "Out of the games there were 1 ties (10.00%)\n"
     ]
    }
   ],
   "source": [
    "print(\" AlphaBeta vs Random\")\n",
    "play_games(alphabeta_player, random_player, 10, (3,4,3))\n",
    "\n",
    "print(\" Random vs AlphaBeta\")\n",
    "play_games(random_player, alphabeta_player, 10, (3,4,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculated the number of number of states expanded by the minimax algorithm, **with and without pruning**, to determine the minimax decision from the initial 6x7 ConnectFour board state.  This can be done in many ways, but writing out all the states by hand is **not** one of them (as you will find out!).\n",
    "\n",
    "I then computed the percent savings that you get by using alpha-beta pruning. i.e. Compute $\\frac{\\text{Number of nodes expanded with pruning}}{\\text{Number of nodes expanded with minimax}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes expanded with minimax: 277167\n",
      "Number of nodes expanded with alpha-beta pruning: 12277\n",
      "Percentage savings with alpha-beta pruning: 95.5705405044612%\n"
     ]
    }
   ],
   "source": [
    "game = ConnectFour(3,4,3)\n",
    "\n",
    "initial_state = game.state\n",
    "\n",
    "# Calculate nodes expanded with minimax\n",
    "nodes_expanded_minimax = 0\n",
    "minimax(game, initial_state, True)\n",
    "print(f\"Number of nodes expanded with minimax: {nodes_expanded_minimax}\")\n",
    "\n",
    "# Calculate nodes expanded with alpha-beta pruning\n",
    "nodes_expanded_ab = alphabeta_player(game, report_nodes_expanded=True)[1]\n",
    "print(f\"Number of nodes expanded with alpha-beta pruning: {nodes_expanded_ab}\")\n",
    "\n",
    "# Compute percentage savings\n",
    "percent_savings = (1 - (nodes_expanded_ab / nodes_expanded_minimax)) * 100\n",
    "print(f\"Percentage savings with alpha-beta pruning: {percent_savings}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the number of nodes expanded by alpha-beta pruning is much smaller than the number of nodes expanded by minimax algorithm in ConnectFour game. This is because alpha-beta pruning avoids exploring branches of the game tree that are unlikely to lead to the best move, while minimax algorithm explores all possible branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating A* search:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a heuristic that will count the number of open runs of three or more consecutive pieces for the current player and the opponent player, and then calculates the minimum distance to a win for the current player and the opponent player in each direction (row, column, diagonal), and returns the minimum value of the distances as the heuristic value.\n",
    "\n",
    "The intuition behind this heuristic is that having more open runs of three or more consecutive pieces increases the player's chances of winning, while having more open runs of the opponent decreases their chances of winning. By calculating the minimum distance to a win for both players in each direction, the heuristic takes into account the potential for the opponent to block the player's runs and for the player to block the opponent's runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(game: ConnectFour, move: tuple[int,int], state: State) -> float:\n",
    "    other_p = Player.BLACK if state.to_move == Player.RED else Player.RED\n",
    "    self_p = state.to_move\n",
    "\n",
    "    heuristics = []\n",
    "    blocks = [[*front, other_p, *back] for front, back in state.get_adjacent(move, game.nwin, [Player.EMPTY, other_p])]\n",
    "    wins = [[*front, self_p, *back] for front, back in state.get_adjacent(move, game.nwin, [Player.EMPTY, self_p])]\n",
    "    for direction_idx in range(len(wins)):\n",
    "        row_wins = wins[direction_idx]\n",
    "        row_blocks = blocks[direction_idx]\n",
    "\n",
    "        dist_win = game.nwin - row_wins.count(self_p) if len(row_wins) >= game.nwin else np.inf\n",
    "        dist_block = game.nwin - row_blocks.count(other_p) if len(row_blocks) >= game.nwin else np.inf\n",
    "        heuristics.append(min(dist_win, dist_block))\n",
    "\n",
    "    heuristic = min(heuristics)\n",
    "    return heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a Uniform Search\n",
    "class Frontier_PQ:\n",
    "    def __init__(self, start_state: State, start_cost: int = 0) -> None:\n",
    "        self.start_state: State = start_state\n",
    "        self.states: Dict[str, Tuple[int, State, Optional[State]]] = {start_state.hash(): (start_cost, start_state, None)}\n",
    "        self.queue: List[Tuple[int, str, Optional[str]]] = [(start_cost, start_state.hash(), None)]\n",
    "\n",
    "    def add(self, state: State, cost: int, parent_state: State):\n",
    "        heapq.heappush(self.queue, [cost, state.hash(), parent_state.hash()])\n",
    "        self.states[state.hash()] = (cost, state, parent_state)\n",
    "    \n",
    "    def pop(self) -> Tuple[int, State, Optional[State]]:\n",
    "        pop_tuple = None\n",
    "        while pop_tuple is None or pop_tuple[0] == \"REMOVED\":\n",
    "            pop_tuple = heapq.heappop(self.queue)\n",
    "            if pop_tuple[0] == \"REMOVED\":\n",
    "                print(\"FOUND REMOVED\")\n",
    "                pop_tuple = None\n",
    "        return self.states.pop(pop_tuple[1])\n",
    "\n",
    "    def replace(self, state: State, new_cost: int, new_parent_state: State):\n",
    "        previous_cost, old_state, old_parent_state = self.states.get(state.hash(), (float('inf'), None, None))    \n",
    "\n",
    "        if new_cost < previous_cost:\n",
    "            self.states[state.hash()] = (new_cost, state, new_parent_state)\n",
    "            for idx, (old_cost, node, old_parent) in enumerate(self.queue):\n",
    "                if node == state.hash():\n",
    "                    self.queue[idx] = (new_cost, node, new_parent_state.hash())\n",
    "                    heapq.heapify(self.queue)\n",
    "                    break\n",
    "            else:\n",
    "                heapq.heappush(self.queue, (new_cost, state.hash(), new_parent_state.hash()))\n",
    "        \n",
    "def path(previous: dict[State, State], s): \n",
    "    if s is None:\n",
    "        return []\n",
    "    else:\n",
    "        return path(previous, previous[s])+[s]\n",
    "\n",
    "\n",
    "def a_star(game: ConnectFour, start_state: State, return_cost=False):\n",
    "    frontier = Frontier_PQ(start_state)\n",
    "    parent_tree: dict[State, State] = {start_state: None}\n",
    "    final_state: State = start_state\n",
    "\n",
    "    while len(frontier.states) != 0:\n",
    "        previous_cost, current_state, parent_state = frontier.pop()\n",
    "        parent_tree[current_state] = parent_state\n",
    "\n",
    "        if game.game_over(current_state):\n",
    "            final_state = current_state\n",
    "            if game.utility(current_state, start_state.to_move) > 0:\n",
    "                break\n",
    "\n",
    "            no_chance_parents = find_no_chance_parents(game, start_state, parent_tree, final_state)\n",
    "            for st in frontier.states:\n",
    "                state_cost, state, parent = frontier.states[st]\n",
    "                if parent in no_chance_parents:\n",
    "                    frontier.replace(state, np.inf, parent)\n",
    "            continue\n",
    "        \n",
    "        explore_children(game, current_state, frontier, parent_tree)\n",
    "    \n",
    "    solution_path = path(parent_tree, final_state)\n",
    "    solution_cost = len(solution_path)\n",
    "    return (solution_path, solution_cost, len(parent_tree.keys())) if return_cost else solution_path\n",
    "\n",
    "\n",
    "def find_no_chance_parents(game, start_state, parent_tree, final_state):\n",
    "    no_chance_parents = [parent_tree[final_state]]\n",
    "    # Stop exploring any branches where they could win in one move from ours.\n",
    "    assert no_chance_parents[0].to_move != start_state.to_move, no_chance_parents[0].to_move + \" != \" + start_state.to_move.name\n",
    "    def bad_children(bad_node: State, d=0):\n",
    "        for key, value in parent_tree.items():\n",
    "            if value == bad_node:\n",
    "                no_chance_parents.append(key)\n",
    "                bad_children(key, d + 1)\n",
    "    bad_children(no_chance_parents[0])\n",
    "    return no_chance_parents\n",
    "\n",
    "\n",
    "def explore_children(game, current_state, frontier, parent_tree):\n",
    "    for action in current_state.moves():\n",
    "        child_state = game.result(action, current_state)\n",
    "        child_path_cost = len(child_state.board) + heuristic(game, action, child_state)\n",
    "\n",
    "        if not child_state in list(parent_tree.keys()) and not child_state in frontier.states:\n",
    "            frontier.add(child_state, child_path_cost, current_state)\n",
    "        elif child_state in frontier.states and frontier.states[child_state] > child_path_cost:\n",
    "            frontier.replace(child_state, child_path_cost, current_state)\n",
    "\n",
    "def a_star_player(game: ConnectFour, return_cost=False):\n",
    "    if return_cost:\n",
    "        solution_path, solution_cost, explored = a_star(game, game.state, True)\n",
    "    else:\n",
    "        solution_path = a_star(game, game.state, False)\n",
    "\n",
    "    for action in game.state.moves():\n",
    "        new_state = game.result(action, game.state)\n",
    "        if new_state.board == solution_path[1].board:\n",
    "            return action\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = ConnectFour(3,4,3)\n",
    "game.play_game(a_star_player, a_star_player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing A* to other algorithms (10 points)\n",
    "Next, I play 10 games of Connect Four using your A* player and a random player and 10 games against the AB pruning player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_moves(games: list[ConnectFour]) -> dict:\n",
    "    all_moves = {p:0 for p in Player}\n",
    "\n",
    "    for game in games:\n",
    "        game_board = game.state.board\n",
    "        for p in game_board.values():\n",
    "            all_moves[p] += 1\n",
    "\n",
    "    return all_moves\n",
    "\n",
    "def display_avg_moves(games: list[ConnectFour]):\n",
    "    all_moves = count_moves(games)\n",
    "    num_games = len(games)\n",
    "\n",
    "    for p, moves in all_moves.items():\n",
    "        print(\"Player {} made {} moves on average across {} games\".format(p.name, moves / num_games, num_games))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 games played between A* player and Alpha-Beta player on a 3x4x3 board with 3 in a row to win.\n",
      "Total number of games played: 10\n",
      "Player RED won 10 games (100.00%)\n",
      "Player BLACK won 0 games (0.00%)\n",
      "Out of the games there were 0 ties (0.00%)\n",
      "Player RED made 6.0 moves on average across 10 games\n",
      "Player BLACK made 5.0 moves on average across 10 games\n",
      "Player EMPTY made 0.0 moves on average across 10 games\n"
     ]
    }
   ],
   "source": [
    "print(\"10 games played between A* player and Alpha-Beta player on a 3x4x3 board with 3 in a row to win.\")\n",
    "moves = play_games(a_star_player, alphabeta_player, 10, (3,4,3), True)\n",
    "display_avg_moves(moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 games played between Alpha-Beta player and Random player on a 3x4x3 board with 3 in a row to win.\n",
      "Total number of games played: 10\n",
      "Player RED won 10 games (100.00%)\n",
      "Player BLACK won 0 games (0.00%)\n",
      "Out of the games there were 0 ties (0.00%)\n",
      "Player RED made 3.1 moves on average across 10 games\n",
      "Player BLACK made 2.1 moves on average across 10 games\n",
      "Player EMPTY made 0.0 moves on average across 10 games\n"
     ]
    }
   ],
   "source": [
    "print(\"10 games played between Alpha-Beta player and Random player on a 3x4x3 board with 3 in a row to win.\")\n",
    "moves = play_games(alphabeta_player, random_player, 10, (3,4,3), True)\n",
    "display_avg_moves(moves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice in the first matchup between Astar and Alphabeta players on a 3x4 board with 3 to win, Astar player emerged as the clear winner. Across 10 games, Astar won all the games while Alphabeta was unable to win any. None of the games resulted in a tie. On average, Astar player made 6 moves while Alphabeta made 5 moves. It is interesting to note that the number of moves made by Astar is more than Alphabeta, indicating that Astar may be exploring more states before making a move.\n",
    "\n",
    "In the second matchup between Alphabeta and Random players on the same board, Alphabeta player won all the games while Random was unable to win any. None of the games resulted in a tie. On average, Alphabeta player made 3.1 moves while Random made 2.1 moves. The difference in the number of moves made by Alphabeta and Random players is quite significant, indicating that Alphabeta is playing more optimally.\n",
    "\n",
    "Based on the outcomes, it appears that Astar and Alphabeta players are stronger than their counterparts. However, the results do not provide conclusive evidence as only a small number of games were played. It is also important to note that the performance of the players may vary depending on the size of the board and the number of moves required to win.\n",
    "\n",
    "In situations where one player appeared to do better than the other, it is possible that the heuristics used by one player were more effective than the other. For example, in the first matchup, Astar may have been better at evaluating the game state and exploring more states before making a move, giving it an advantage over Alphabeta. In the second matchup, Alphabeta may have been better at analyzing the game state and choosing the best move, giving it an advantage over Random.\n",
    "\n",
    "To further improve the performance of the players, other heuristics can be implemented. For example, one can use a combination of heuristics to evaluate the game state, such as considering the number of pieces in a row, column, or diagonal, and the number of open spaces. Additionally, one can implement a search algorithm that is more efficient than Astar or Alphabeta, such as Iterative Deepening Search. Overall, the results suggest that both Astar and Alphabeta players are strong, but their performance can be further improved with additional heuristics and search algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
